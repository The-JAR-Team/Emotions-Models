{
  "best_global_step": 2472,
  "best_metric": 0.34264079507808803,
  "best_model_checkpoint": "./emotion_transformer_affectnet_model\\training_checkpoints\\checkpoint-2472",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3090,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0970873786407767,
      "grad_norm": 1.9026061296463013,
      "learning_rate": 9.385113268608415e-06,
      "loss": 2.1313,
      "step": 30
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 1.5918831825256348,
      "learning_rate": 1.9093851132686084e-05,
      "loss": 2.0868,
      "step": 60
    },
    {
      "epoch": 0.2912621359223301,
      "grad_norm": 1.0824097394943237,
      "learning_rate": 2.880258899676376e-05,
      "loss": 2.0692,
      "step": 90
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 1.4531916379928589,
      "learning_rate": 3.8511326860841424e-05,
      "loss": 2.0593,
      "step": 120
    },
    {
      "epoch": 0.4854368932038835,
      "grad_norm": 1.0364331007003784,
      "learning_rate": 4.82200647249191e-05,
      "loss": 2.0577,
      "step": 150
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 1.822874665260315,
      "learning_rate": 5.7928802588996766e-05,
      "loss": 2.0434,
      "step": 180
    },
    {
      "epoch": 0.6796116504854369,
      "grad_norm": 1.9900604486465454,
      "learning_rate": 6.763754045307443e-05,
      "loss": 2.0522,
      "step": 210
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 1.8907878398895264,
      "learning_rate": 7.734627831715211e-05,
      "loss": 2.0263,
      "step": 240
    },
    {
      "epoch": 0.8737864077669902,
      "grad_norm": 2.0211081504821777,
      "learning_rate": 8.705501618122978e-05,
      "loss": 2.0305,
      "step": 270
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 1.782634973526001,
      "learning_rate": 9.676375404530746e-05,
      "loss": 2.0282,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.2352106010411737,
      "eval_f1": 0.17004313104146834,
      "eval_loss": 2.0057358741760254,
      "eval_precision": 0.16087801879488964,
      "eval_recall": 0.2352106010411737,
      "eval_runtime": 79.2549,
      "eval_samples_per_second": 53.322,
      "eval_steps_per_second": 0.845,
      "step": 309
    },
    {
      "epoch": 1.0679611650485437,
      "grad_norm": 1.3616043329238892,
      "learning_rate": 9.928083423229055e-05,
      "loss": 2.0072,
      "step": 330
    },
    {
      "epoch": 1.1650485436893203,
      "grad_norm": 1.5945097208023071,
      "learning_rate": 9.820208558072636e-05,
      "loss": 2.0031,
      "step": 360
    },
    {
      "epoch": 1.262135922330097,
      "grad_norm": 2.1019692420959473,
      "learning_rate": 9.712333692916218e-05,
      "loss": 1.9942,
      "step": 390
    },
    {
      "epoch": 1.3592233009708738,
      "grad_norm": 2.9892690181732178,
      "learning_rate": 9.604458827759798e-05,
      "loss": 1.9702,
      "step": 420
    },
    {
      "epoch": 1.4563106796116505,
      "grad_norm": 2.477174758911133,
      "learning_rate": 9.49658396260338e-05,
      "loss": 1.9634,
      "step": 450
    },
    {
      "epoch": 1.5533980582524272,
      "grad_norm": 1.7410128116607666,
      "learning_rate": 9.388709097446962e-05,
      "loss": 1.9341,
      "step": 480
    },
    {
      "epoch": 1.650485436893204,
      "grad_norm": 5.996518135070801,
      "learning_rate": 9.280834232290544e-05,
      "loss": 1.9138,
      "step": 510
    },
    {
      "epoch": 1.7475728155339807,
      "grad_norm": 2.3450376987457275,
      "learning_rate": 9.172959367134126e-05,
      "loss": 1.8822,
      "step": 540
    },
    {
      "epoch": 1.8446601941747574,
      "grad_norm": 3.4805829524993896,
      "learning_rate": 9.065084501977706e-05,
      "loss": 1.8919,
      "step": 570
    },
    {
      "epoch": 1.941747572815534,
      "grad_norm": 3.122628927230835,
      "learning_rate": 8.957209636821288e-05,
      "loss": 1.8388,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.2574538570752485,
      "eval_f1": 0.18419357174529108,
      "eval_loss": 1.982999563217163,
      "eval_precision": 0.3162970002386641,
      "eval_recall": 0.2574538570752485,
      "eval_runtime": 36.8126,
      "eval_samples_per_second": 114.798,
      "eval_steps_per_second": 1.82,
      "step": 618
    },
    {
      "epoch": 2.0388349514563107,
      "grad_norm": 2.8101158142089844,
      "learning_rate": 8.84933477166487e-05,
      "loss": 1.8711,
      "step": 630
    },
    {
      "epoch": 2.1359223300970873,
      "grad_norm": 2.4819250106811523,
      "learning_rate": 8.74145990650845e-05,
      "loss": 1.852,
      "step": 660
    },
    {
      "epoch": 2.233009708737864,
      "grad_norm": 3.1149890422821045,
      "learning_rate": 8.633585041352033e-05,
      "loss": 1.8133,
      "step": 690
    },
    {
      "epoch": 2.3300970873786406,
      "grad_norm": 3.827481508255005,
      "learning_rate": 8.525710176195613e-05,
      "loss": 1.8151,
      "step": 720
    },
    {
      "epoch": 2.4271844660194173,
      "grad_norm": 5.3921332359313965,
      "learning_rate": 8.417835311039195e-05,
      "loss": 1.7951,
      "step": 750
    },
    {
      "epoch": 2.524271844660194,
      "grad_norm": 8.49852466583252,
      "learning_rate": 8.309960445882776e-05,
      "loss": 1.8422,
      "step": 780
    },
    {
      "epoch": 2.6213592233009706,
      "grad_norm": 2.702418565750122,
      "learning_rate": 8.202085580726357e-05,
      "loss": 1.8321,
      "step": 810
    },
    {
      "epoch": 2.7184466019417477,
      "grad_norm": 6.874489784240723,
      "learning_rate": 8.094210715569939e-05,
      "loss": 1.8171,
      "step": 840
    },
    {
      "epoch": 2.8155339805825244,
      "grad_norm": 7.294247627258301,
      "learning_rate": 7.986335850413521e-05,
      "loss": 1.7839,
      "step": 870
    },
    {
      "epoch": 2.912621359223301,
      "grad_norm": 5.665092468261719,
      "learning_rate": 7.878460985257103e-05,
      "loss": 1.7912,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.3118788452437293,
      "eval_f1": 0.24567651884821845,
      "eval_loss": 1.8214138746261597,
      "eval_precision": 0.286052672357711,
      "eval_recall": 0.3118788452437293,
      "eval_runtime": 36.8103,
      "eval_samples_per_second": 114.805,
      "eval_steps_per_second": 1.82,
      "step": 927
    },
    {
      "epoch": 3.0097087378640777,
      "grad_norm": 4.908616065979004,
      "learning_rate": 7.770586120100683e-05,
      "loss": 1.7927,
      "step": 930
    },
    {
      "epoch": 3.1067961165048543,
      "grad_norm": 4.579701900482178,
      "learning_rate": 7.662711254944265e-05,
      "loss": 1.7807,
      "step": 960
    },
    {
      "epoch": 3.203883495145631,
      "grad_norm": 2.5261833667755127,
      "learning_rate": 7.554836389787847e-05,
      "loss": 1.7916,
      "step": 990
    },
    {
      "epoch": 3.3009708737864076,
      "grad_norm": 5.371024131774902,
      "learning_rate": 7.446961524631428e-05,
      "loss": 1.7763,
      "step": 1020
    },
    {
      "epoch": 3.3980582524271843,
      "grad_norm": 3.3087801933288574,
      "learning_rate": 7.33908665947501e-05,
      "loss": 1.7681,
      "step": 1050
    },
    {
      "epoch": 3.4951456310679614,
      "grad_norm": 6.1399946212768555,
      "learning_rate": 7.23121179431859e-05,
      "loss": 1.7872,
      "step": 1080
    },
    {
      "epoch": 3.592233009708738,
      "grad_norm": 3.3598875999450684,
      "learning_rate": 7.123336929162172e-05,
      "loss": 1.7788,
      "step": 1110
    },
    {
      "epoch": 3.6893203883495147,
      "grad_norm": 4.02352237701416,
      "learning_rate": 7.015462064005753e-05,
      "loss": 1.7647,
      "step": 1140
    },
    {
      "epoch": 3.7864077669902914,
      "grad_norm": 8.251214981079102,
      "learning_rate": 6.907587198849335e-05,
      "loss": 1.766,
      "step": 1170
    },
    {
      "epoch": 3.883495145631068,
      "grad_norm": 6.273728847503662,
      "learning_rate": 6.799712333692916e-05,
      "loss": 1.7658,
      "step": 1200
    },
    {
      "epoch": 3.9805825242718447,
      "grad_norm": 6.800903797149658,
      "learning_rate": 6.691837468536498e-05,
      "loss": 1.7798,
      "step": 1230
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.3225272124940842,
      "eval_f1": 0.2565086283170201,
      "eval_loss": 1.7676831483840942,
      "eval_precision": 0.3238898172215738,
      "eval_recall": 0.3225272124940842,
      "eval_runtime": 36.7773,
      "eval_samples_per_second": 114.908,
      "eval_steps_per_second": 1.822,
      "step": 1236
    },
    {
      "epoch": 4.077669902912621,
      "grad_norm": 6.288231372833252,
      "learning_rate": 6.58396260338008e-05,
      "loss": 1.7626,
      "step": 1260
    },
    {
      "epoch": 4.174757281553398,
      "grad_norm": 8.043922424316406,
      "learning_rate": 6.47608773822366e-05,
      "loss": 1.7568,
      "step": 1290
    },
    {
      "epoch": 4.271844660194175,
      "grad_norm": 13.278958320617676,
      "learning_rate": 6.368212873067242e-05,
      "loss": 1.7446,
      "step": 1320
    },
    {
      "epoch": 4.368932038834951,
      "grad_norm": 5.422540187835693,
      "learning_rate": 6.260338007910824e-05,
      "loss": 1.7791,
      "step": 1350
    },
    {
      "epoch": 4.466019417475728,
      "grad_norm": 3.489809989929199,
      "learning_rate": 6.152463142754406e-05,
      "loss": 1.7659,
      "step": 1380
    },
    {
      "epoch": 4.563106796116505,
      "grad_norm": 5.574561595916748,
      "learning_rate": 6.044588277597987e-05,
      "loss": 1.7797,
      "step": 1410
    },
    {
      "epoch": 4.660194174757281,
      "grad_norm": 3.438232421875,
      "learning_rate": 5.936713412441568e-05,
      "loss": 1.7386,
      "step": 1440
    },
    {
      "epoch": 4.757281553398058,
      "grad_norm": 5.917951583862305,
      "learning_rate": 5.828838547285149e-05,
      "loss": 1.7375,
      "step": 1470
    },
    {
      "epoch": 4.854368932038835,
      "grad_norm": 2.844677686691284,
      "learning_rate": 5.720963682128731e-05,
      "loss": 1.7911,
      "step": 1500
    },
    {
      "epoch": 4.951456310679612,
      "grad_norm": 3.053659677505493,
      "learning_rate": 5.613088816972313e-05,
      "loss": 1.7701,
      "step": 1530
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.29815428300993846,
      "eval_f1": 0.2311895299078492,
      "eval_loss": 1.8822448253631592,
      "eval_precision": 0.2943237702634274,
      "eval_recall": 0.29815428300993846,
      "eval_runtime": 37.3184,
      "eval_samples_per_second": 113.242,
      "eval_steps_per_second": 1.795,
      "step": 1545
    },
    {
      "epoch": 5.048543689320389,
      "grad_norm": 2.794278383255005,
      "learning_rate": 5.505213951815894e-05,
      "loss": 1.7538,
      "step": 1560
    },
    {
      "epoch": 5.145631067961165,
      "grad_norm": 4.07630729675293,
      "learning_rate": 5.397339086659475e-05,
      "loss": 1.7368,
      "step": 1590
    },
    {
      "epoch": 5.242718446601942,
      "grad_norm": 5.796375274658203,
      "learning_rate": 5.2894642215030564e-05,
      "loss": 1.7612,
      "step": 1620
    },
    {
      "epoch": 5.339805825242719,
      "grad_norm": 3.143965005874634,
      "learning_rate": 5.1815893563466375e-05,
      "loss": 1.7511,
      "step": 1650
    },
    {
      "epoch": 5.436893203883495,
      "grad_norm": 3.9818549156188965,
      "learning_rate": 5.07371449119022e-05,
      "loss": 1.7456,
      "step": 1680
    },
    {
      "epoch": 5.533980582524272,
      "grad_norm": 3.33024263381958,
      "learning_rate": 4.965839626033801e-05,
      "loss": 1.7555,
      "step": 1710
    },
    {
      "epoch": 5.631067961165049,
      "grad_norm": 3.0793566703796387,
      "learning_rate": 4.857964760877383e-05,
      "loss": 1.7142,
      "step": 1740
    },
    {
      "epoch": 5.728155339805825,
      "grad_norm": 4.543182373046875,
      "learning_rate": 4.750089895720964e-05,
      "loss": 1.7371,
      "step": 1770
    },
    {
      "epoch": 5.825242718446602,
      "grad_norm": 6.256781101226807,
      "learning_rate": 4.642215030564545e-05,
      "loss": 1.7286,
      "step": 1800
    },
    {
      "epoch": 5.922330097087379,
      "grad_norm": 8.075484275817871,
      "learning_rate": 4.534340165408127e-05,
      "loss": 1.7386,
      "step": 1830
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.32039753904401325,
      "eval_f1": 0.2659703120989249,
      "eval_loss": 1.806251883506775,
      "eval_precision": 0.3274648640484856,
      "eval_recall": 0.32039753904401325,
      "eval_runtime": 36.9927,
      "eval_samples_per_second": 114.239,
      "eval_steps_per_second": 1.811,
      "step": 1854
    },
    {
      "epoch": 6.019417475728155,
      "grad_norm": 3.3110973834991455,
      "learning_rate": 4.426465300251708e-05,
      "loss": 1.7791,
      "step": 1860
    },
    {
      "epoch": 6.116504854368932,
      "grad_norm": 3.365497350692749,
      "learning_rate": 4.3185904350952896e-05,
      "loss": 1.7221,
      "step": 1890
    },
    {
      "epoch": 6.213592233009709,
      "grad_norm": 3.0182552337646484,
      "learning_rate": 4.2107155699388714e-05,
      "loss": 1.7205,
      "step": 1920
    },
    {
      "epoch": 6.310679611650485,
      "grad_norm": 2.41239857673645,
      "learning_rate": 4.1028407047824525e-05,
      "loss": 1.7205,
      "step": 1950
    },
    {
      "epoch": 6.407766990291262,
      "grad_norm": 2.208120584487915,
      "learning_rate": 3.994965839626034e-05,
      "loss": 1.7217,
      "step": 1980
    },
    {
      "epoch": 6.504854368932039,
      "grad_norm": 3.3639063835144043,
      "learning_rate": 3.887090974469615e-05,
      "loss": 1.7244,
      "step": 2010
    },
    {
      "epoch": 6.601941747572815,
      "grad_norm": 5.499973773956299,
      "learning_rate": 3.7792161093131964e-05,
      "loss": 1.7626,
      "step": 2040
    },
    {
      "epoch": 6.699029126213592,
      "grad_norm": 3.090808391571045,
      "learning_rate": 3.671341244156778e-05,
      "loss": 1.7257,
      "step": 2070
    },
    {
      "epoch": 6.796116504854369,
      "grad_norm": 7.268554210662842,
      "learning_rate": 3.56346637900036e-05,
      "loss": 1.7396,
      "step": 2100
    },
    {
      "epoch": 6.893203883495145,
      "grad_norm": 2.8032007217407227,
      "learning_rate": 3.455591513843941e-05,
      "loss": 1.7593,
      "step": 2130
    },
    {
      "epoch": 6.990291262135923,
      "grad_norm": 5.977023124694824,
      "learning_rate": 3.347716648687523e-05,
      "loss": 1.7064,
      "step": 2160
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.34051112162801705,
      "eval_f1": 0.30295223466544846,
      "eval_loss": 1.749774694442749,
      "eval_precision": 0.3493314725467854,
      "eval_recall": 0.34051112162801705,
      "eval_runtime": 38.0698,
      "eval_samples_per_second": 111.007,
      "eval_steps_per_second": 1.76,
      "step": 2163
    },
    {
      "epoch": 7.087378640776699,
      "grad_norm": 2.4509780406951904,
      "learning_rate": 3.239841783531104e-05,
      "loss": 1.7025,
      "step": 2190
    },
    {
      "epoch": 7.184466019417476,
      "grad_norm": 4.287092685699463,
      "learning_rate": 3.131966918374685e-05,
      "loss": 1.6975,
      "step": 2220
    },
    {
      "epoch": 7.281553398058253,
      "grad_norm": 8.072750091552734,
      "learning_rate": 3.024092053218267e-05,
      "loss": 1.7362,
      "step": 2250
    },
    {
      "epoch": 7.378640776699029,
      "grad_norm": 3.605107069015503,
      "learning_rate": 2.9162171880618482e-05,
      "loss": 1.713,
      "step": 2280
    },
    {
      "epoch": 7.475728155339806,
      "grad_norm": 6.374732971191406,
      "learning_rate": 2.80834232290543e-05,
      "loss": 1.6945,
      "step": 2310
    },
    {
      "epoch": 7.572815533980583,
      "grad_norm": 2.699587345123291,
      "learning_rate": 2.7004674577490114e-05,
      "loss": 1.7122,
      "step": 2340
    },
    {
      "epoch": 7.669902912621359,
      "grad_norm": 4.047435283660889,
      "learning_rate": 2.5925925925925925e-05,
      "loss": 1.7097,
      "step": 2370
    },
    {
      "epoch": 7.766990291262136,
      "grad_norm": 2.9489293098449707,
      "learning_rate": 2.4847177274361743e-05,
      "loss": 1.7059,
      "step": 2400
    },
    {
      "epoch": 7.864077669902913,
      "grad_norm": 6.437814712524414,
      "learning_rate": 2.3768428622797557e-05,
      "loss": 1.7271,
      "step": 2430
    },
    {
      "epoch": 7.961165048543689,
      "grad_norm": 4.7325334548950195,
      "learning_rate": 2.268967997123337e-05,
      "loss": 1.7276,
      "step": 2460
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.34264079507808803,
      "eval_f1": 0.2825908847443193,
      "eval_loss": 1.7410211563110352,
      "eval_precision": 0.33246346088954026,
      "eval_recall": 0.34264079507808803,
      "eval_runtime": 37.7506,
      "eval_samples_per_second": 111.945,
      "eval_steps_per_second": 1.775,
      "step": 2472
    },
    {
      "epoch": 8.058252427184467,
      "grad_norm": 2.9010603427886963,
      "learning_rate": 2.1610931319669182e-05,
      "loss": 1.7328,
      "step": 2490
    },
    {
      "epoch": 8.155339805825243,
      "grad_norm": 2.545728921890259,
      "learning_rate": 2.0532182668105e-05,
      "loss": 1.7062,
      "step": 2520
    },
    {
      "epoch": 8.25242718446602,
      "grad_norm": 5.573504447937012,
      "learning_rate": 1.9453434016540814e-05,
      "loss": 1.7433,
      "step": 2550
    },
    {
      "epoch": 8.349514563106796,
      "grad_norm": 2.572319269180298,
      "learning_rate": 1.837468536497663e-05,
      "loss": 1.6713,
      "step": 2580
    },
    {
      "epoch": 8.446601941747574,
      "grad_norm": 7.0669846534729,
      "learning_rate": 1.7295936713412443e-05,
      "loss": 1.7205,
      "step": 2610
    },
    {
      "epoch": 8.54368932038835,
      "grad_norm": 3.04598069190979,
      "learning_rate": 1.6217188061848257e-05,
      "loss": 1.714,
      "step": 2640
    },
    {
      "epoch": 8.640776699029127,
      "grad_norm": 2.472977876663208,
      "learning_rate": 1.5138439410284071e-05,
      "loss": 1.7111,
      "step": 2670
    },
    {
      "epoch": 8.737864077669903,
      "grad_norm": 4.112051963806152,
      "learning_rate": 1.4059690758719884e-05,
      "loss": 1.6944,
      "step": 2700
    },
    {
      "epoch": 8.83495145631068,
      "grad_norm": 5.272604942321777,
      "learning_rate": 1.29809421071557e-05,
      "loss": 1.6974,
      "step": 2730
    },
    {
      "epoch": 8.932038834951456,
      "grad_norm": 4.634581565856934,
      "learning_rate": 1.1902193455591514e-05,
      "loss": 1.6979,
      "step": 2760
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.3331755797444392,
      "eval_f1": 0.2922128722497054,
      "eval_loss": 1.7688666582107544,
      "eval_precision": 0.3461146630493165,
      "eval_recall": 0.3331755797444392,
      "eval_runtime": 39.1991,
      "eval_samples_per_second": 107.809,
      "eval_steps_per_second": 1.709,
      "step": 2781
    },
    {
      "epoch": 9.029126213592233,
      "grad_norm": 2.736802577972412,
      "learning_rate": 1.0823444804027329e-05,
      "loss": 1.6998,
      "step": 2790
    },
    {
      "epoch": 9.12621359223301,
      "grad_norm": 4.750362873077393,
      "learning_rate": 9.744696152463145e-06,
      "loss": 1.7053,
      "step": 2820
    },
    {
      "epoch": 9.223300970873787,
      "grad_norm": 2.264561653137207,
      "learning_rate": 8.665947500898957e-06,
      "loss": 1.684,
      "step": 2850
    },
    {
      "epoch": 9.320388349514563,
      "grad_norm": 2.562295436859131,
      "learning_rate": 7.5871988493347715e-06,
      "loss": 1.7027,
      "step": 2880
    },
    {
      "epoch": 9.41747572815534,
      "grad_norm": 9.25947380065918,
      "learning_rate": 6.508450197770587e-06,
      "loss": 1.7114,
      "step": 2910
    },
    {
      "epoch": 9.514563106796116,
      "grad_norm": 3.202054977416992,
      "learning_rate": 5.429701546206401e-06,
      "loss": 1.7179,
      "step": 2940
    },
    {
      "epoch": 9.611650485436893,
      "grad_norm": 3.8379619121551514,
      "learning_rate": 4.350952894642215e-06,
      "loss": 1.6731,
      "step": 2970
    },
    {
      "epoch": 9.70873786407767,
      "grad_norm": 4.01182222366333,
      "learning_rate": 3.2722042430780295e-06,
      "loss": 1.7009,
      "step": 3000
    },
    {
      "epoch": 9.805825242718447,
      "grad_norm": 5.111264228820801,
      "learning_rate": 2.193455591513844e-06,
      "loss": 1.6999,
      "step": 3030
    },
    {
      "epoch": 9.902912621359224,
      "grad_norm": 9.41082763671875,
      "learning_rate": 1.1147069399496584e-06,
      "loss": 1.6973,
      "step": 3060
    },
    {
      "epoch": 10.0,
      "grad_norm": 14.209696769714355,
      "learning_rate": 3.595828838547285e-08,
      "loss": 1.7001,
      "step": 3090
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.33483199242782774,
      "eval_f1": 0.28392200362278447,
      "eval_loss": 1.7754594087600708,
      "eval_precision": 0.366117198622259,
      "eval_recall": 0.33483199242782774,
      "eval_runtime": 37.1844,
      "eval_samples_per_second": 113.65,
      "eval_steps_per_second": 1.802,
      "step": 3090
    }
  ],
  "logging_steps": 30,
  "max_steps": 3090,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
