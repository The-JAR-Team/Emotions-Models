{
  "best_global_step": 2163,
  "best_metric": 0.34051112162801705,
  "best_model_checkpoint": "./emotion_transformer_affectnet_model\\training_checkpoints\\checkpoint-2163",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 2163,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0970873786407767,
      "grad_norm": 1.9026061296463013,
      "learning_rate": 9.385113268608415e-06,
      "loss": 2.1313,
      "step": 30
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 1.5918831825256348,
      "learning_rate": 1.9093851132686084e-05,
      "loss": 2.0868,
      "step": 60
    },
    {
      "epoch": 0.2912621359223301,
      "grad_norm": 1.0824097394943237,
      "learning_rate": 2.880258899676376e-05,
      "loss": 2.0692,
      "step": 90
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 1.4531916379928589,
      "learning_rate": 3.8511326860841424e-05,
      "loss": 2.0593,
      "step": 120
    },
    {
      "epoch": 0.4854368932038835,
      "grad_norm": 1.0364331007003784,
      "learning_rate": 4.82200647249191e-05,
      "loss": 2.0577,
      "step": 150
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 1.822874665260315,
      "learning_rate": 5.7928802588996766e-05,
      "loss": 2.0434,
      "step": 180
    },
    {
      "epoch": 0.6796116504854369,
      "grad_norm": 1.9900604486465454,
      "learning_rate": 6.763754045307443e-05,
      "loss": 2.0522,
      "step": 210
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 1.8907878398895264,
      "learning_rate": 7.734627831715211e-05,
      "loss": 2.0263,
      "step": 240
    },
    {
      "epoch": 0.8737864077669902,
      "grad_norm": 2.0211081504821777,
      "learning_rate": 8.705501618122978e-05,
      "loss": 2.0305,
      "step": 270
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 1.782634973526001,
      "learning_rate": 9.676375404530746e-05,
      "loss": 2.0282,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.2352106010411737,
      "eval_f1": 0.17004313104146834,
      "eval_loss": 2.0057358741760254,
      "eval_precision": 0.16087801879488964,
      "eval_recall": 0.2352106010411737,
      "eval_runtime": 79.2549,
      "eval_samples_per_second": 53.322,
      "eval_steps_per_second": 0.845,
      "step": 309
    },
    {
      "epoch": 1.0679611650485437,
      "grad_norm": 1.3616043329238892,
      "learning_rate": 9.928083423229055e-05,
      "loss": 2.0072,
      "step": 330
    },
    {
      "epoch": 1.1650485436893203,
      "grad_norm": 1.5945097208023071,
      "learning_rate": 9.820208558072636e-05,
      "loss": 2.0031,
      "step": 360
    },
    {
      "epoch": 1.262135922330097,
      "grad_norm": 2.1019692420959473,
      "learning_rate": 9.712333692916218e-05,
      "loss": 1.9942,
      "step": 390
    },
    {
      "epoch": 1.3592233009708738,
      "grad_norm": 2.9892690181732178,
      "learning_rate": 9.604458827759798e-05,
      "loss": 1.9702,
      "step": 420
    },
    {
      "epoch": 1.4563106796116505,
      "grad_norm": 2.477174758911133,
      "learning_rate": 9.49658396260338e-05,
      "loss": 1.9634,
      "step": 450
    },
    {
      "epoch": 1.5533980582524272,
      "grad_norm": 1.7410128116607666,
      "learning_rate": 9.388709097446962e-05,
      "loss": 1.9341,
      "step": 480
    },
    {
      "epoch": 1.650485436893204,
      "grad_norm": 5.996518135070801,
      "learning_rate": 9.280834232290544e-05,
      "loss": 1.9138,
      "step": 510
    },
    {
      "epoch": 1.7475728155339807,
      "grad_norm": 2.3450376987457275,
      "learning_rate": 9.172959367134126e-05,
      "loss": 1.8822,
      "step": 540
    },
    {
      "epoch": 1.8446601941747574,
      "grad_norm": 3.4805829524993896,
      "learning_rate": 9.065084501977706e-05,
      "loss": 1.8919,
      "step": 570
    },
    {
      "epoch": 1.941747572815534,
      "grad_norm": 3.122628927230835,
      "learning_rate": 8.957209636821288e-05,
      "loss": 1.8388,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.2574538570752485,
      "eval_f1": 0.18419357174529108,
      "eval_loss": 1.982999563217163,
      "eval_precision": 0.3162970002386641,
      "eval_recall": 0.2574538570752485,
      "eval_runtime": 36.8126,
      "eval_samples_per_second": 114.798,
      "eval_steps_per_second": 1.82,
      "step": 618
    },
    {
      "epoch": 2.0388349514563107,
      "grad_norm": 2.8101158142089844,
      "learning_rate": 8.84933477166487e-05,
      "loss": 1.8711,
      "step": 630
    },
    {
      "epoch": 2.1359223300970873,
      "grad_norm": 2.4819250106811523,
      "learning_rate": 8.74145990650845e-05,
      "loss": 1.852,
      "step": 660
    },
    {
      "epoch": 2.233009708737864,
      "grad_norm": 3.1149890422821045,
      "learning_rate": 8.633585041352033e-05,
      "loss": 1.8133,
      "step": 690
    },
    {
      "epoch": 2.3300970873786406,
      "grad_norm": 3.827481508255005,
      "learning_rate": 8.525710176195613e-05,
      "loss": 1.8151,
      "step": 720
    },
    {
      "epoch": 2.4271844660194173,
      "grad_norm": 5.3921332359313965,
      "learning_rate": 8.417835311039195e-05,
      "loss": 1.7951,
      "step": 750
    },
    {
      "epoch": 2.524271844660194,
      "grad_norm": 8.49852466583252,
      "learning_rate": 8.309960445882776e-05,
      "loss": 1.8422,
      "step": 780
    },
    {
      "epoch": 2.6213592233009706,
      "grad_norm": 2.702418565750122,
      "learning_rate": 8.202085580726357e-05,
      "loss": 1.8321,
      "step": 810
    },
    {
      "epoch": 2.7184466019417477,
      "grad_norm": 6.874489784240723,
      "learning_rate": 8.094210715569939e-05,
      "loss": 1.8171,
      "step": 840
    },
    {
      "epoch": 2.8155339805825244,
      "grad_norm": 7.294247627258301,
      "learning_rate": 7.986335850413521e-05,
      "loss": 1.7839,
      "step": 870
    },
    {
      "epoch": 2.912621359223301,
      "grad_norm": 5.665092468261719,
      "learning_rate": 7.878460985257103e-05,
      "loss": 1.7912,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.3118788452437293,
      "eval_f1": 0.24567651884821845,
      "eval_loss": 1.8214138746261597,
      "eval_precision": 0.286052672357711,
      "eval_recall": 0.3118788452437293,
      "eval_runtime": 36.8103,
      "eval_samples_per_second": 114.805,
      "eval_steps_per_second": 1.82,
      "step": 927
    },
    {
      "epoch": 3.0097087378640777,
      "grad_norm": 4.908616065979004,
      "learning_rate": 7.770586120100683e-05,
      "loss": 1.7927,
      "step": 930
    },
    {
      "epoch": 3.1067961165048543,
      "grad_norm": 4.579701900482178,
      "learning_rate": 7.662711254944265e-05,
      "loss": 1.7807,
      "step": 960
    },
    {
      "epoch": 3.203883495145631,
      "grad_norm": 2.5261833667755127,
      "learning_rate": 7.554836389787847e-05,
      "loss": 1.7916,
      "step": 990
    },
    {
      "epoch": 3.3009708737864076,
      "grad_norm": 5.371024131774902,
      "learning_rate": 7.446961524631428e-05,
      "loss": 1.7763,
      "step": 1020
    },
    {
      "epoch": 3.3980582524271843,
      "grad_norm": 3.3087801933288574,
      "learning_rate": 7.33908665947501e-05,
      "loss": 1.7681,
      "step": 1050
    },
    {
      "epoch": 3.4951456310679614,
      "grad_norm": 6.1399946212768555,
      "learning_rate": 7.23121179431859e-05,
      "loss": 1.7872,
      "step": 1080
    },
    {
      "epoch": 3.592233009708738,
      "grad_norm": 3.3598875999450684,
      "learning_rate": 7.123336929162172e-05,
      "loss": 1.7788,
      "step": 1110
    },
    {
      "epoch": 3.6893203883495147,
      "grad_norm": 4.02352237701416,
      "learning_rate": 7.015462064005753e-05,
      "loss": 1.7647,
      "step": 1140
    },
    {
      "epoch": 3.7864077669902914,
      "grad_norm": 8.251214981079102,
      "learning_rate": 6.907587198849335e-05,
      "loss": 1.766,
      "step": 1170
    },
    {
      "epoch": 3.883495145631068,
      "grad_norm": 6.273728847503662,
      "learning_rate": 6.799712333692916e-05,
      "loss": 1.7658,
      "step": 1200
    },
    {
      "epoch": 3.9805825242718447,
      "grad_norm": 6.800903797149658,
      "learning_rate": 6.691837468536498e-05,
      "loss": 1.7798,
      "step": 1230
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.3225272124940842,
      "eval_f1": 0.2565086283170201,
      "eval_loss": 1.7676831483840942,
      "eval_precision": 0.3238898172215738,
      "eval_recall": 0.3225272124940842,
      "eval_runtime": 36.7773,
      "eval_samples_per_second": 114.908,
      "eval_steps_per_second": 1.822,
      "step": 1236
    },
    {
      "epoch": 4.077669902912621,
      "grad_norm": 6.288231372833252,
      "learning_rate": 6.58396260338008e-05,
      "loss": 1.7626,
      "step": 1260
    },
    {
      "epoch": 4.174757281553398,
      "grad_norm": 8.043922424316406,
      "learning_rate": 6.47608773822366e-05,
      "loss": 1.7568,
      "step": 1290
    },
    {
      "epoch": 4.271844660194175,
      "grad_norm": 13.278958320617676,
      "learning_rate": 6.368212873067242e-05,
      "loss": 1.7446,
      "step": 1320
    },
    {
      "epoch": 4.368932038834951,
      "grad_norm": 5.422540187835693,
      "learning_rate": 6.260338007910824e-05,
      "loss": 1.7791,
      "step": 1350
    },
    {
      "epoch": 4.466019417475728,
      "grad_norm": 3.489809989929199,
      "learning_rate": 6.152463142754406e-05,
      "loss": 1.7659,
      "step": 1380
    },
    {
      "epoch": 4.563106796116505,
      "grad_norm": 5.574561595916748,
      "learning_rate": 6.044588277597987e-05,
      "loss": 1.7797,
      "step": 1410
    },
    {
      "epoch": 4.660194174757281,
      "grad_norm": 3.438232421875,
      "learning_rate": 5.936713412441568e-05,
      "loss": 1.7386,
      "step": 1440
    },
    {
      "epoch": 4.757281553398058,
      "grad_norm": 5.917951583862305,
      "learning_rate": 5.828838547285149e-05,
      "loss": 1.7375,
      "step": 1470
    },
    {
      "epoch": 4.854368932038835,
      "grad_norm": 2.844677686691284,
      "learning_rate": 5.720963682128731e-05,
      "loss": 1.7911,
      "step": 1500
    },
    {
      "epoch": 4.951456310679612,
      "grad_norm": 3.053659677505493,
      "learning_rate": 5.613088816972313e-05,
      "loss": 1.7701,
      "step": 1530
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.29815428300993846,
      "eval_f1": 0.2311895299078492,
      "eval_loss": 1.8822448253631592,
      "eval_precision": 0.2943237702634274,
      "eval_recall": 0.29815428300993846,
      "eval_runtime": 37.3184,
      "eval_samples_per_second": 113.242,
      "eval_steps_per_second": 1.795,
      "step": 1545
    },
    {
      "epoch": 5.048543689320389,
      "grad_norm": 2.794278383255005,
      "learning_rate": 5.505213951815894e-05,
      "loss": 1.7538,
      "step": 1560
    },
    {
      "epoch": 5.145631067961165,
      "grad_norm": 4.07630729675293,
      "learning_rate": 5.397339086659475e-05,
      "loss": 1.7368,
      "step": 1590
    },
    {
      "epoch": 5.242718446601942,
      "grad_norm": 5.796375274658203,
      "learning_rate": 5.2894642215030564e-05,
      "loss": 1.7612,
      "step": 1620
    },
    {
      "epoch": 5.339805825242719,
      "grad_norm": 3.143965005874634,
      "learning_rate": 5.1815893563466375e-05,
      "loss": 1.7511,
      "step": 1650
    },
    {
      "epoch": 5.436893203883495,
      "grad_norm": 3.9818549156188965,
      "learning_rate": 5.07371449119022e-05,
      "loss": 1.7456,
      "step": 1680
    },
    {
      "epoch": 5.533980582524272,
      "grad_norm": 3.33024263381958,
      "learning_rate": 4.965839626033801e-05,
      "loss": 1.7555,
      "step": 1710
    },
    {
      "epoch": 5.631067961165049,
      "grad_norm": 3.0793566703796387,
      "learning_rate": 4.857964760877383e-05,
      "loss": 1.7142,
      "step": 1740
    },
    {
      "epoch": 5.728155339805825,
      "grad_norm": 4.543182373046875,
      "learning_rate": 4.750089895720964e-05,
      "loss": 1.7371,
      "step": 1770
    },
    {
      "epoch": 5.825242718446602,
      "grad_norm": 6.256781101226807,
      "learning_rate": 4.642215030564545e-05,
      "loss": 1.7286,
      "step": 1800
    },
    {
      "epoch": 5.922330097087379,
      "grad_norm": 8.075484275817871,
      "learning_rate": 4.534340165408127e-05,
      "loss": 1.7386,
      "step": 1830
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.32039753904401325,
      "eval_f1": 0.2659703120989249,
      "eval_loss": 1.806251883506775,
      "eval_precision": 0.3274648640484856,
      "eval_recall": 0.32039753904401325,
      "eval_runtime": 36.9927,
      "eval_samples_per_second": 114.239,
      "eval_steps_per_second": 1.811,
      "step": 1854
    },
    {
      "epoch": 6.019417475728155,
      "grad_norm": 3.3110973834991455,
      "learning_rate": 4.426465300251708e-05,
      "loss": 1.7791,
      "step": 1860
    },
    {
      "epoch": 6.116504854368932,
      "grad_norm": 3.365497350692749,
      "learning_rate": 4.3185904350952896e-05,
      "loss": 1.7221,
      "step": 1890
    },
    {
      "epoch": 6.213592233009709,
      "grad_norm": 3.0182552337646484,
      "learning_rate": 4.2107155699388714e-05,
      "loss": 1.7205,
      "step": 1920
    },
    {
      "epoch": 6.310679611650485,
      "grad_norm": 2.41239857673645,
      "learning_rate": 4.1028407047824525e-05,
      "loss": 1.7205,
      "step": 1950
    },
    {
      "epoch": 6.407766990291262,
      "grad_norm": 2.208120584487915,
      "learning_rate": 3.994965839626034e-05,
      "loss": 1.7217,
      "step": 1980
    },
    {
      "epoch": 6.504854368932039,
      "grad_norm": 3.3639063835144043,
      "learning_rate": 3.887090974469615e-05,
      "loss": 1.7244,
      "step": 2010
    },
    {
      "epoch": 6.601941747572815,
      "grad_norm": 5.499973773956299,
      "learning_rate": 3.7792161093131964e-05,
      "loss": 1.7626,
      "step": 2040
    },
    {
      "epoch": 6.699029126213592,
      "grad_norm": 3.090808391571045,
      "learning_rate": 3.671341244156778e-05,
      "loss": 1.7257,
      "step": 2070
    },
    {
      "epoch": 6.796116504854369,
      "grad_norm": 7.268554210662842,
      "learning_rate": 3.56346637900036e-05,
      "loss": 1.7396,
      "step": 2100
    },
    {
      "epoch": 6.893203883495145,
      "grad_norm": 2.8032007217407227,
      "learning_rate": 3.455591513843941e-05,
      "loss": 1.7593,
      "step": 2130
    },
    {
      "epoch": 6.990291262135923,
      "grad_norm": 5.977023124694824,
      "learning_rate": 3.347716648687523e-05,
      "loss": 1.7064,
      "step": 2160
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.34051112162801705,
      "eval_f1": 0.30295223466544846,
      "eval_loss": 1.749774694442749,
      "eval_precision": 0.3493314725467854,
      "eval_recall": 0.34051112162801705,
      "eval_runtime": 38.0698,
      "eval_samples_per_second": 111.007,
      "eval_steps_per_second": 1.76,
      "step": 2163
    }
  ],
  "logging_steps": 30,
  "max_steps": 3090,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
