{
  "best_global_step": 618,
  "best_metric": 0.23710364410790347,
  "best_model_checkpoint": "./emotion_transformer_affectnet_model\\training_checkpoints\\checkpoint-618",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 927,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0970873786407767,
      "grad_norm": 1.4196053743362427,
      "learning_rate": 1.8770226537216826e-05,
      "loss": 2.1151,
      "step": 30
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 1.7625056505203247,
      "learning_rate": 3.818770226537217e-05,
      "loss": 2.0752,
      "step": 60
    },
    {
      "epoch": 0.2912621359223301,
      "grad_norm": 1.1654430627822876,
      "learning_rate": 5.760517799352751e-05,
      "loss": 2.0647,
      "step": 90
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 1.5210850238800049,
      "learning_rate": 7.702265372168285e-05,
      "loss": 2.0545,
      "step": 120
    },
    {
      "epoch": 0.4854368932038835,
      "grad_norm": 1.0808846950531006,
      "learning_rate": 9.64401294498382e-05,
      "loss": 2.0477,
      "step": 150
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 1.7602348327636719,
      "learning_rate": 0.00011585760517799353,
      "loss": 2.0128,
      "step": 180
    },
    {
      "epoch": 0.6796116504854369,
      "grad_norm": 1.8402427434921265,
      "learning_rate": 0.00013527508090614888,
      "loss": 2.0161,
      "step": 210
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 2.2782669067382812,
      "learning_rate": 0.00015469255663430422,
      "loss": 1.9557,
      "step": 240
    },
    {
      "epoch": 0.8737864077669902,
      "grad_norm": 1.8832720518112183,
      "learning_rate": 0.00017411003236245955,
      "loss": 1.9378,
      "step": 270
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 3.286592721939087,
      "learning_rate": 0.0001935275080906149,
      "loss": 1.9017,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.12659725508755323,
      "eval_f1": 0.05821493535450691,
      "eval_loss": 2.697575330734253,
      "eval_precision": 0.2433542411659881,
      "eval_recall": 0.12659725508755323,
      "eval_runtime": 38.6566,
      "eval_samples_per_second": 109.322,
      "eval_steps_per_second": 1.733,
      "step": 309
    },
    {
      "epoch": 1.0679611650485437,
      "grad_norm": 2.3194971084594727,
      "learning_rate": 0.00021294498381877022,
      "loss": 1.8527,
      "step": 330
    },
    {
      "epoch": 1.1650485436893203,
      "grad_norm": 5.361942768096924,
      "learning_rate": 0.00023236245954692556,
      "loss": 1.8497,
      "step": 360
    },
    {
      "epoch": 1.262135922330097,
      "grad_norm": 12.76817512512207,
      "learning_rate": 0.0002517799352750809,
      "loss": 1.9026,
      "step": 390
    },
    {
      "epoch": 1.3592233009708738,
      "grad_norm": 8.686102867126465,
      "learning_rate": 0.00027119741100323626,
      "loss": 1.9209,
      "step": 420
    },
    {
      "epoch": 1.4563106796116505,
      "grad_norm": 3.3824708461761475,
      "learning_rate": 0.00029061488673139157,
      "loss": 1.9589,
      "step": 450
    },
    {
      "epoch": 1.5533980582524272,
      "grad_norm": 2.4984757900238037,
      "learning_rate": 0.00031003236245954693,
      "loss": 1.8792,
      "step": 480
    },
    {
      "epoch": 1.650485436893204,
      "grad_norm": 2.3143608570098877,
      "learning_rate": 0.0003294498381877023,
      "loss": 1.8503,
      "step": 510
    },
    {
      "epoch": 1.7475728155339807,
      "grad_norm": 4.316702365875244,
      "learning_rate": 0.00034886731391585766,
      "loss": 1.8267,
      "step": 540
    },
    {
      "epoch": 1.8446601941747574,
      "grad_norm": 4.186056137084961,
      "learning_rate": 0.00036828478964401296,
      "loss": 1.8195,
      "step": 570
    },
    {
      "epoch": 1.941747572815534,
      "grad_norm": 2.0863072872161865,
      "learning_rate": 0.0003877022653721683,
      "loss": 1.8609,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.23710364410790347,
      "eval_f1": 0.1654489293843238,
      "eval_loss": 2.162806510925293,
      "eval_precision": 0.2213003272568578,
      "eval_recall": 0.23710364410790347,
      "eval_runtime": 38.4626,
      "eval_samples_per_second": 109.873,
      "eval_steps_per_second": 1.742,
      "step": 618
    },
    {
      "epoch": 2.0388349514563107,
      "grad_norm": 5.802969932556152,
      "learning_rate": 0.00040711974110032364,
      "loss": 1.8701,
      "step": 630
    },
    {
      "epoch": 2.1359223300970873,
      "grad_norm": 2.7275643348693848,
      "learning_rate": 0.00042653721682847894,
      "loss": 1.846,
      "step": 660
    },
    {
      "epoch": 2.233009708737864,
      "grad_norm": 4.404341697692871,
      "learning_rate": 0.0004459546925566343,
      "loss": 1.7998,
      "step": 690
    },
    {
      "epoch": 2.3300970873786406,
      "grad_norm": 12.191619873046875,
      "learning_rate": 0.00046537216828478967,
      "loss": 1.8187,
      "step": 720
    },
    {
      "epoch": 2.4271844660194173,
      "grad_norm": 7.048086166381836,
      "learning_rate": 0.00048478964401294503,
      "loss": 1.8344,
      "step": 750
    },
    {
      "epoch": 2.524271844660194,
      "grad_norm": 2.4963796138763428,
      "learning_rate": 0.0005042071197411003,
      "loss": 1.8262,
      "step": 780
    },
    {
      "epoch": 2.6213592233009706,
      "grad_norm": 4.1460137367248535,
      "learning_rate": 0.0005236245954692557,
      "loss": 1.8432,
      "step": 810
    },
    {
      "epoch": 2.7184466019417477,
      "grad_norm": 2.7393922805786133,
      "learning_rate": 0.000543042071197411,
      "loss": 1.8289,
      "step": 840
    },
    {
      "epoch": 2.8155339805825244,
      "grad_norm": 7.549488544464111,
      "learning_rate": 0.0005624595469255663,
      "loss": 1.7824,
      "step": 870
    },
    {
      "epoch": 2.912621359223301,
      "grad_norm": 4.655762672424316,
      "learning_rate": 0.0005818770226537216,
      "loss": 1.803,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.18906767628963558,
      "eval_f1": 0.10285732981195354,
      "eval_loss": 2.475020408630371,
      "eval_precision": 0.2151173548931148,
      "eval_recall": 0.18906767628963558,
      "eval_runtime": 39.3182,
      "eval_samples_per_second": 107.482,
      "eval_steps_per_second": 1.704,
      "step": 927
    }
  ],
  "logging_steps": 30,
  "max_steps": 15450,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
